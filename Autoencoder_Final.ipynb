{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.layers.core import Reshape\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.convolutional import MaxPooling2D,UpSampling2D,Conv2DTranspose\n",
    "from keras.layers.convolutional import Convolution2D as Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import merge\n",
    "from keras.optimizers import Adadelta, RMSprop\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from numpy import * \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import scipy.misc\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "\n",
    "    input_img = Input(shape=(128,128,1))\n",
    "    conv1 = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "      \n",
    "    conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "       \n",
    "    conv3 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    \n",
    "    up6 = UpSampling2D((2,2))(conv5)\n",
    "    up6 = merge([up6, conv4], mode='concat', concat_axis=3)\n",
    "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    \n",
    "    up7 = UpSampling2D((2,2))(conv6)\n",
    "    up7 = merge([up7, conv3], mode='concat', concat_axis=3)\n",
    "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    \n",
    "    up8 = UpSampling2D((2,2))(conv7)\n",
    "    up8 = merge([up8, conv2], mode='concat', concat_axis=3)\n",
    "    conv8 = Conv2D(32, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    \n",
    "    up9 = UpSampling2D((2,2))(conv8)\n",
    "    up9 = merge([up9, conv1], mode='concat', concat_axis=3)\n",
    "    conv9 = Conv2D(16, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "       \n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(conv9)\n",
    "    \n",
    "    ada=Adadelta(lr=5.0, rho=0.95, epsilon=1e-08, decay=0.001)\n",
    "    rms=RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.001)\n",
    "    \n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(loss='mean_squared_error', optimizer=rms)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:34: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:41: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:48: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:55: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "autoencoder=model()\n",
    "\n",
    "basic_mat=[]\n",
    "tobe_mat=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path1=\"Data_M\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data, Converting it from RGB to Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,123):\n",
    "    path_major=path1+'/'+str(i)\n",
    "    for j in range(1,100):\n",
    "        img=array(Image.open(path_major+\"/\"+str(j)+\"_.jpg\"))\n",
    "        #print shape(img)\n",
    "        img = cv2.cvtColor( img, cv2.COLOR_RGB2GRAY )\n",
    "        img=img.reshape(128,128,1)\n",
    "        basic_mat.append(img)\n",
    "        tobe_mat.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data,Label = shuffle(basic_mat,tobe_mat, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting the Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878, 128, 128, 1)\n",
      "(878, 128, 128, 1)\n",
      "(220, 128, 128, 1)\n",
      "(220, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, Label, test_size=0.2, random_state=2)\n",
    "X_train = array(X_train)\n",
    "y_train = array(y_train)\n",
    "X_test = array(X_test)\n",
    "y_test = array(y_test)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalising the Values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = X_train.astype('float32') / 255.\n",
    "x_test = X_test.astype('float32') / 255.\n",
    "\n",
    "y_train = y_train.astype('float32') / 255.\n",
    "y_test = y_test.astype('float32') / 255.\n",
    "CheckDir = 'sample/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is: 1\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 1 batch_num: 0 loss: 0.126357\n",
      "\n",
      "epoch_num: 1 batch_num: 1 loss: 0.045475\n",
      "\n",
      "epoch_num: 1 batch_num: 2 loss: 0.036353\n",
      "\n",
      "epoch_num: 1 batch_num: 3 loss: 0.020744\n",
      "\n",
      "epoch_num: 1 batch_num: 4 loss: 0.017121\n",
      "\n",
      "epoch_num: 1 batch_num: 5 loss: 0.014984\n",
      "\n",
      "Epoch is: 2\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 2 batch_num: 0 loss: 0.011565\n",
      "\n",
      "epoch_num: 2 batch_num: 1 loss: 0.009701\n",
      "\n",
      "epoch_num: 2 batch_num: 2 loss: 0.007675\n",
      "\n",
      "epoch_num: 2 batch_num: 3 loss: 0.006582\n",
      "\n",
      "epoch_num: 2 batch_num: 4 loss: 0.005638\n",
      "\n",
      "epoch_num: 2 batch_num: 5 loss: 0.005281\n",
      "\n",
      "Epoch is: 3\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 3 batch_num: 0 loss: 0.004274\n",
      "\n",
      "epoch_num: 3 batch_num: 1 loss: 0.005603\n",
      "\n",
      "epoch_num: 3 batch_num: 2 loss: 0.004505\n",
      "\n",
      "epoch_num: 3 batch_num: 3 loss: 0.004315\n",
      "\n",
      "epoch_num: 3 batch_num: 4 loss: 0.003987\n",
      "\n",
      "epoch_num: 3 batch_num: 5 loss: 0.004229\n",
      "\n",
      "Epoch is: 4\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 4 batch_num: 0 loss: 0.003600\n",
      "\n",
      "epoch_num: 4 batch_num: 1 loss: 0.003876\n",
      "\n",
      "epoch_num: 4 batch_num: 2 loss: 0.003966\n",
      "\n",
      "epoch_num: 4 batch_num: 3 loss: 0.004587\n",
      "\n",
      "epoch_num: 4 batch_num: 4 loss: 0.004666\n",
      "\n",
      "epoch_num: 4 batch_num: 5 loss: 0.005202\n",
      "\n",
      "Epoch is: 5\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 5 batch_num: 0 loss: 0.003237\n",
      "\n",
      "epoch_num: 5 batch_num: 1 loss: 0.003037\n",
      "\n",
      "epoch_num: 5 batch_num: 2 loss: 0.003040\n",
      "\n",
      "epoch_num: 5 batch_num: 3 loss: 0.003251\n",
      "\n",
      "epoch_num: 5 batch_num: 4 loss: 0.003154\n",
      "\n",
      "epoch_num: 5 batch_num: 5 loss: 0.003435\n",
      "\n",
      "Epoch is: 6\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 6 batch_num: 0 loss: 0.002597\n",
      "\n",
      "epoch_num: 6 batch_num: 1 loss: 0.002627\n",
      "\n",
      "epoch_num: 6 batch_num: 2 loss: 0.002421\n",
      "\n",
      "epoch_num: 6 batch_num: 3 loss: 0.002325\n",
      "\n",
      "epoch_num: 6 batch_num: 4 loss: 0.002698\n",
      "\n",
      "epoch_num: 6 batch_num: 5 loss: 0.002699\n",
      "\n",
      "Epoch is: 7\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 7 batch_num: 0 loss: 0.002811\n",
      "\n",
      "epoch_num: 7 batch_num: 1 loss: 0.002576\n",
      "\n",
      "epoch_num: 7 batch_num: 2 loss: 0.003757\n",
      "\n",
      "epoch_num: 7 batch_num: 3 loss: 0.002797\n",
      "\n",
      "epoch_num: 7 batch_num: 4 loss: 0.002297\n",
      "\n",
      "epoch_num: 7 batch_num: 5 loss: 0.002015\n",
      "\n",
      "Epoch is: 8\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 8 batch_num: 0 loss: 0.002000\n",
      "\n",
      "epoch_num: 8 batch_num: 1 loss: 0.002825\n",
      "\n",
      "epoch_num: 8 batch_num: 2 loss: 0.003963\n",
      "\n",
      "epoch_num: 8 batch_num: 3 loss: 0.003811\n",
      "\n",
      "epoch_num: 8 batch_num: 4 loss: 0.002916\n",
      "\n",
      "epoch_num: 8 batch_num: 5 loss: 0.002065\n",
      "\n",
      "Epoch is: 9\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 9 batch_num: 0 loss: 0.001777\n",
      "\n",
      "epoch_num: 9 batch_num: 1 loss: 0.001828\n",
      "\n",
      "epoch_num: 9 batch_num: 2 loss: 0.001998\n",
      "\n",
      "epoch_num: 9 batch_num: 3 loss: 0.002403\n",
      "\n",
      "epoch_num: 9 batch_num: 4 loss: 0.001657\n",
      "\n",
      "epoch_num: 9 batch_num: 5 loss: 0.001897\n",
      "\n",
      "Epoch is: 10\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 10 batch_num: 0 loss: 0.001883\n",
      "\n",
      "epoch_num: 10 batch_num: 1 loss: 0.001884\n",
      "\n",
      "epoch_num: 10 batch_num: 2 loss: 0.001831\n",
      "\n",
      "epoch_num: 10 batch_num: 3 loss: 0.001883\n",
      "\n",
      "epoch_num: 10 batch_num: 4 loss: 0.001509\n",
      "\n",
      "epoch_num: 10 batch_num: 5 loss: 0.001876\n",
      "\n",
      "Epoch is: 11\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 11 batch_num: 0 loss: 0.002096\n",
      "\n",
      "epoch_num: 11 batch_num: 1 loss: 0.002203\n",
      "\n",
      "epoch_num: 11 batch_num: 2 loss: 0.001985\n",
      "\n",
      "epoch_num: 11 batch_num: 3 loss: 0.001806\n",
      "\n",
      "epoch_num: 11 batch_num: 4 loss: 0.001850\n",
      "\n",
      "epoch_num: 11 batch_num: 5 loss: 0.001944\n",
      "\n",
      "Epoch is: 12\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 12 batch_num: 0 loss: 0.002150\n",
      "\n",
      "epoch_num: 12 batch_num: 1 loss: 0.001228\n",
      "\n",
      "epoch_num: 12 batch_num: 2 loss: 0.001359\n",
      "\n",
      "epoch_num: 12 batch_num: 3 loss: 0.001382\n",
      "\n",
      "epoch_num: 12 batch_num: 4 loss: 0.001128\n",
      "\n",
      "epoch_num: 12 batch_num: 5 loss: 0.001066\n",
      "\n",
      "Epoch is: 13\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 13 batch_num: 0 loss: 0.001506\n",
      "\n",
      "epoch_num: 13 batch_num: 1 loss: 0.002340\n",
      "\n",
      "epoch_num: 13 batch_num: 2 loss: 0.002759\n",
      "\n",
      "epoch_num: 13 batch_num: 3 loss: 0.001497\n",
      "\n",
      "epoch_num: 13 batch_num: 4 loss: 0.003073\n",
      "\n",
      "epoch_num: 13 batch_num: 5 loss: 0.003714\n",
      "\n",
      "Epoch is: 14\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 14 batch_num: 0 loss: 0.002635\n",
      "\n",
      "epoch_num: 14 batch_num: 1 loss: 0.001687\n",
      "\n",
      "epoch_num: 14 batch_num: 2 loss: 0.001422\n",
      "\n",
      "epoch_num: 14 batch_num: 3 loss: 0.001677\n",
      "\n",
      "epoch_num: 14 batch_num: 4 loss: 0.001616\n",
      "\n",
      "epoch_num: 14 batch_num: 5 loss: 0.001401\n",
      "\n",
      "Epoch is: 15\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 15 batch_num: 0 loss: 0.001346\n",
      "\n",
      "epoch_num: 15 batch_num: 1 loss: 0.001104\n",
      "\n",
      "epoch_num: 15 batch_num: 2 loss: 0.001094\n",
      "\n",
      "epoch_num: 15 batch_num: 3 loss: 0.000971\n",
      "\n",
      "epoch_num: 15 batch_num: 4 loss: 0.000955\n",
      "\n",
      "epoch_num: 15 batch_num: 5 loss: 0.001084\n",
      "\n",
      "Epoch is: 16\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 16 batch_num: 0 loss: 0.001025\n",
      "\n",
      "epoch_num: 16 batch_num: 1 loss: 0.001228\n",
      "\n",
      "epoch_num: 16 batch_num: 2 loss: 0.000973\n",
      "\n",
      "epoch_num: 16 batch_num: 3 loss: 0.001442\n",
      "\n",
      "epoch_num: 16 batch_num: 4 loss: 0.001009\n",
      "\n",
      "epoch_num: 16 batch_num: 5 loss: 0.000908\n",
      "\n",
      "Epoch is: 17\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 17 batch_num: 0 loss: 0.001148\n",
      "\n",
      "epoch_num: 17 batch_num: 1 loss: 0.001307\n",
      "\n",
      "epoch_num: 17 batch_num: 2 loss: 0.001293\n",
      "\n",
      "epoch_num: 17 batch_num: 3 loss: 0.001557\n",
      "\n",
      "epoch_num: 17 batch_num: 4 loss: 0.001005\n",
      "\n",
      "epoch_num: 17 batch_num: 5 loss: 0.001324\n",
      "\n",
      "Epoch is: 18\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 18 batch_num: 0 loss: 0.001535\n",
      "\n",
      "epoch_num: 18 batch_num: 1 loss: 0.001819\n",
      "\n",
      "epoch_num: 18 batch_num: 2 loss: 0.001115\n",
      "\n",
      "epoch_num: 18 batch_num: 3 loss: 0.000749\n",
      "\n",
      "epoch_num: 18 batch_num: 4 loss: 0.001300\n",
      "\n",
      "epoch_num: 18 batch_num: 5 loss: 0.001135\n",
      "\n",
      "Epoch is: 19\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 19 batch_num: 0 loss: 0.001083\n",
      "\n",
      "epoch_num: 19 batch_num: 1 loss: 0.001055\n",
      "\n",
      "epoch_num: 19 batch_num: 2 loss: 0.000823\n",
      "\n",
      "epoch_num: 19 batch_num: 3 loss: 0.000862\n",
      "\n",
      "epoch_num: 19 batch_num: 4 loss: 0.001247\n",
      "\n",
      "epoch_num: 19 batch_num: 5 loss: 0.001125\n",
      "\n",
      "Epoch is: 20\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 20 batch_num: 0 loss: 0.001443\n",
      "\n",
      "epoch_num: 20 batch_num: 1 loss: 0.001429\n",
      "\n",
      "epoch_num: 20 batch_num: 2 loss: 0.000778\n",
      "\n",
      "epoch_num: 20 batch_num: 3 loss: 0.000617\n",
      "\n",
      "epoch_num: 20 batch_num: 4 loss: 0.000643\n",
      "\n",
      "epoch_num: 20 batch_num: 5 loss: 0.000739\n",
      "\n",
      "Epoch is: 21\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 21 batch_num: 0 loss: 0.000745\n",
      "\n",
      "epoch_num: 21 batch_num: 1 loss: 0.000875\n",
      "\n",
      "epoch_num: 21 batch_num: 2 loss: 0.000807\n",
      "\n",
      "epoch_num: 21 batch_num: 3 loss: 0.000877\n",
      "\n",
      "epoch_num: 21 batch_num: 4 loss: 0.000895\n",
      "\n",
      "epoch_num: 21 batch_num: 5 loss: 0.001158\n",
      "\n",
      "Epoch is: 22\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 22 batch_num: 0 loss: 0.001026\n",
      "\n",
      "epoch_num: 22 batch_num: 1 loss: 0.001062\n",
      "\n",
      "epoch_num: 22 batch_num: 2 loss: 0.001344\n",
      "\n",
      "epoch_num: 22 batch_num: 3 loss: 0.001194\n",
      "\n",
      "epoch_num: 22 batch_num: 4 loss: 0.000923\n",
      "\n",
      "epoch_num: 22 batch_num: 5 loss: 0.000613\n",
      "\n",
      "Epoch is: 23\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 23 batch_num: 0 loss: 0.000783\n",
      "\n",
      "epoch_num: 23 batch_num: 1 loss: 0.000612\n",
      "\n",
      "epoch_num: 23 batch_num: 2 loss: 0.000878\n",
      "\n",
      "epoch_num: 23 batch_num: 3 loss: 0.000725\n",
      "\n",
      "epoch_num: 23 batch_num: 4 loss: 0.000799\n",
      "\n",
      "epoch_num: 23 batch_num: 5 loss: 0.000770\n",
      "\n",
      "Epoch is: 24\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 24 batch_num: 0 loss: 0.000869\n",
      "\n",
      "epoch_num: 24 batch_num: 1 loss: 0.001187\n",
      "\n",
      "epoch_num: 24 batch_num: 2 loss: 0.001358\n",
      "\n",
      "epoch_num: 24 batch_num: 3 loss: 0.001171\n",
      "\n",
      "epoch_num: 24 batch_num: 4 loss: 0.001728\n",
      "\n",
      "epoch_num: 24 batch_num: 5 loss: 0.001518\n",
      "\n",
      "Epoch is: 25\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 25 batch_num: 0 loss: 0.000964\n",
      "\n",
      "epoch_num: 25 batch_num: 1 loss: 0.000773\n",
      "\n",
      "epoch_num: 25 batch_num: 2 loss: 0.000637\n",
      "\n",
      "epoch_num: 25 batch_num: 3 loss: 0.000443\n",
      "\n",
      "epoch_num: 25 batch_num: 4 loss: 0.000783\n",
      "\n",
      "epoch_num: 25 batch_num: 5 loss: 0.000628\n",
      "\n",
      "Epoch is: 26\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 26 batch_num: 0 loss: 0.000755\n",
      "\n",
      "epoch_num: 26 batch_num: 1 loss: 0.000589\n",
      "\n",
      "epoch_num: 26 batch_num: 2 loss: 0.000907\n",
      "\n",
      "epoch_num: 26 batch_num: 3 loss: 0.000666\n",
      "\n",
      "epoch_num: 26 batch_num: 4 loss: 0.000758\n",
      "\n",
      "epoch_num: 26 batch_num: 5 loss: 0.000886\n",
      "\n",
      "Epoch is: 27\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 27 batch_num: 0 loss: 0.000808\n",
      "\n",
      "epoch_num: 27 batch_num: 1 loss: 0.000659\n",
      "\n",
      "epoch_num: 27 batch_num: 2 loss: 0.000999\n",
      "\n",
      "epoch_num: 27 batch_num: 3 loss: 0.000952\n",
      "\n",
      "epoch_num: 27 batch_num: 4 loss: 0.000810\n",
      "\n",
      "epoch_num: 27 batch_num: 5 loss: 0.000782\n",
      "\n",
      "Epoch is: 28\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 28 batch_num: 0 loss: 0.000592\n",
      "\n",
      "epoch_num: 28 batch_num: 1 loss: 0.000780\n",
      "\n",
      "epoch_num: 28 batch_num: 2 loss: 0.000950\n",
      "\n",
      "epoch_num: 28 batch_num: 3 loss: 0.000543\n",
      "\n",
      "epoch_num: 28 batch_num: 4 loss: 0.000576\n",
      "\n",
      "epoch_num: 28 batch_num: 5 loss: 0.000558\n",
      "\n",
      "Epoch is: 29\n",
      "\n",
      "Number of batches: 6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num: 29 batch_num: 0 loss: 0.000447\n",
      "\n",
      "epoch_num: 29 batch_num: 1 loss: 0.000541\n",
      "\n",
      "epoch_num: 29 batch_num: 2 loss: 0.000691\n",
      "\n",
      "epoch_num: 29 batch_num: 3 loss: 0.000687\n",
      "\n",
      "epoch_num: 29 batch_num: 4 loss: 0.000690\n",
      "\n",
      "epoch_num: 29 batch_num: 5 loss: 0.000745\n",
      "\n",
      "Epoch is: 30\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 30 batch_num: 0 loss: 0.000786\n",
      "\n",
      "epoch_num: 30 batch_num: 1 loss: 0.000777\n",
      "\n",
      "epoch_num: 30 batch_num: 2 loss: 0.000984\n",
      "\n",
      "epoch_num: 30 batch_num: 3 loss: 0.000604\n",
      "\n",
      "epoch_num: 30 batch_num: 4 loss: 0.000658\n",
      "\n",
      "epoch_num: 30 batch_num: 5 loss: 0.000780\n",
      "\n",
      "Epoch is: 31\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 31 batch_num: 0 loss: 0.000656\n",
      "\n",
      "epoch_num: 31 batch_num: 1 loss: 0.000757\n",
      "\n",
      "epoch_num: 31 batch_num: 2 loss: 0.000556\n",
      "\n",
      "epoch_num: 31 batch_num: 3 loss: 0.000473\n",
      "\n",
      "epoch_num: 31 batch_num: 4 loss: 0.000341\n",
      "\n",
      "epoch_num: 31 batch_num: 5 loss: 0.000805\n",
      "\n",
      "Epoch is: 32\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 32 batch_num: 0 loss: 0.001043\n",
      "\n",
      "epoch_num: 32 batch_num: 1 loss: 0.001562\n",
      "\n",
      "epoch_num: 32 batch_num: 2 loss: 0.000925\n",
      "\n",
      "epoch_num: 32 batch_num: 3 loss: 0.000460\n",
      "\n",
      "epoch_num: 32 batch_num: 4 loss: 0.000345\n",
      "\n",
      "epoch_num: 32 batch_num: 5 loss: 0.000614\n",
      "\n",
      "Epoch is: 33\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 33 batch_num: 0 loss: 0.000548\n",
      "\n",
      "epoch_num: 33 batch_num: 1 loss: 0.000782\n",
      "\n",
      "epoch_num: 33 batch_num: 2 loss: 0.000960\n",
      "\n",
      "epoch_num: 33 batch_num: 3 loss: 0.000710\n",
      "\n",
      "epoch_num: 33 batch_num: 4 loss: 0.000750\n",
      "\n",
      "epoch_num: 33 batch_num: 5 loss: 0.000513\n",
      "\n",
      "Epoch is: 34\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 34 batch_num: 0 loss: 0.000377\n",
      "\n",
      "epoch_num: 34 batch_num: 1 loss: 0.000461\n",
      "\n",
      "epoch_num: 34 batch_num: 2 loss: 0.000670\n",
      "\n",
      "epoch_num: 34 batch_num: 3 loss: 0.000660\n",
      "\n",
      "epoch_num: 34 batch_num: 4 loss: 0.000632\n",
      "\n",
      "epoch_num: 34 batch_num: 5 loss: 0.000380\n",
      "\n",
      "Epoch is: 35\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 35 batch_num: 0 loss: 0.000754\n",
      "\n",
      "epoch_num: 35 batch_num: 1 loss: 0.000840\n",
      "\n",
      "epoch_num: 35 batch_num: 2 loss: 0.000817\n",
      "\n",
      "epoch_num: 35 batch_num: 3 loss: 0.000795\n",
      "\n",
      "epoch_num: 35 batch_num: 4 loss: 0.000720\n",
      "\n",
      "epoch_num: 35 batch_num: 5 loss: 0.000455\n",
      "\n",
      "Epoch is: 36\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 36 batch_num: 0 loss: 0.000461\n",
      "\n",
      "epoch_num: 36 batch_num: 1 loss: 0.000429\n",
      "\n",
      "epoch_num: 36 batch_num: 2 loss: 0.000551\n",
      "\n",
      "epoch_num: 36 batch_num: 3 loss: 0.000597\n",
      "\n",
      "epoch_num: 36 batch_num: 4 loss: 0.000781\n",
      "\n",
      "epoch_num: 36 batch_num: 5 loss: 0.000564\n",
      "\n",
      "Epoch is: 37\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 37 batch_num: 0 loss: 0.000700\n",
      "\n",
      "epoch_num: 37 batch_num: 1 loss: 0.000351\n",
      "\n",
      "epoch_num: 37 batch_num: 2 loss: 0.000405\n",
      "\n",
      "epoch_num: 37 batch_num: 3 loss: 0.000421\n",
      "\n",
      "epoch_num: 37 batch_num: 4 loss: 0.000547\n",
      "\n",
      "epoch_num: 37 batch_num: 5 loss: 0.000366\n",
      "\n",
      "Epoch is: 38\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 38 batch_num: 0 loss: 0.000501\n",
      "\n",
      "epoch_num: 38 batch_num: 1 loss: 0.000790\n",
      "\n",
      "epoch_num: 38 batch_num: 2 loss: 0.001093\n",
      "\n",
      "epoch_num: 38 batch_num: 3 loss: 0.000731\n",
      "\n",
      "epoch_num: 38 batch_num: 4 loss: 0.000412\n",
      "\n",
      "epoch_num: 38 batch_num: 5 loss: 0.000373\n",
      "\n",
      "Epoch is: 39\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 39 batch_num: 0 loss: 0.000328\n",
      "\n",
      "epoch_num: 39 batch_num: 1 loss: 0.000350\n",
      "\n",
      "epoch_num: 39 batch_num: 2 loss: 0.000371\n",
      "\n",
      "epoch_num: 39 batch_num: 3 loss: 0.000303\n",
      "\n",
      "epoch_num: 39 batch_num: 4 loss: 0.000384\n",
      "\n",
      "epoch_num: 39 batch_num: 5 loss: 0.000365\n",
      "\n",
      "Epoch is: 40\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 40 batch_num: 0 loss: 0.000470\n",
      "\n",
      "epoch_num: 40 batch_num: 1 loss: 0.000598\n",
      "\n",
      "epoch_num: 40 batch_num: 2 loss: 0.000626\n",
      "\n",
      "epoch_num: 40 batch_num: 3 loss: 0.000712\n",
      "\n",
      "epoch_num: 40 batch_num: 4 loss: 0.000475\n",
      "\n",
      "epoch_num: 40 batch_num: 5 loss: 0.000506\n",
      "\n",
      "Epoch is: 41\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 41 batch_num: 0 loss: 0.000414\n",
      "\n",
      "epoch_num: 41 batch_num: 1 loss: 0.000369\n",
      "\n",
      "epoch_num: 41 batch_num: 2 loss: 0.000291\n",
      "\n",
      "epoch_num: 41 batch_num: 3 loss: 0.000363\n",
      "\n",
      "epoch_num: 41 batch_num: 4 loss: 0.000902\n",
      "\n",
      "epoch_num: 41 batch_num: 5 loss: 0.001209\n",
      "\n",
      "Epoch is: 42\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 42 batch_num: 0 loss: 0.000534\n",
      "\n",
      "epoch_num: 42 batch_num: 1 loss: 0.000439\n",
      "\n",
      "epoch_num: 42 batch_num: 2 loss: 0.000443\n",
      "\n",
      "epoch_num: 42 batch_num: 3 loss: 0.000431\n",
      "\n",
      "epoch_num: 42 batch_num: 4 loss: 0.000651\n",
      "\n",
      "epoch_num: 42 batch_num: 5 loss: 0.000417\n",
      "\n",
      "Epoch is: 43\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 43 batch_num: 0 loss: 0.000374\n",
      "\n",
      "epoch_num: 43 batch_num: 1 loss: 0.000349\n",
      "\n",
      "epoch_num: 43 batch_num: 2 loss: 0.000413\n",
      "\n",
      "epoch_num: 43 batch_num: 3 loss: 0.000419\n",
      "\n",
      "epoch_num: 43 batch_num: 4 loss: 0.000634\n",
      "\n",
      "epoch_num: 43 batch_num: 5 loss: 0.000474\n",
      "\n",
      "Epoch is: 44\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 44 batch_num: 0 loss: 0.000405\n",
      "\n",
      "epoch_num: 44 batch_num: 1 loss: 0.000500\n",
      "\n",
      "epoch_num: 44 batch_num: 2 loss: 0.000485\n",
      "\n",
      "epoch_num: 44 batch_num: 3 loss: 0.000567\n",
      "\n",
      "epoch_num: 44 batch_num: 4 loss: 0.000546\n",
      "\n",
      "epoch_num: 44 batch_num: 5 loss: 0.000329\n",
      "\n",
      "Epoch is: 45\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 45 batch_num: 0 loss: 0.000288\n",
      "\n",
      "epoch_num: 45 batch_num: 1 loss: 0.000358\n",
      "\n",
      "epoch_num: 45 batch_num: 2 loss: 0.000504\n",
      "\n",
      "epoch_num: 45 batch_num: 3 loss: 0.000371\n",
      "\n",
      "epoch_num: 45 batch_num: 4 loss: 0.000312\n",
      "\n",
      "epoch_num: 45 batch_num: 5 loss: 0.000652\n",
      "\n",
      "Epoch is: 46\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 46 batch_num: 0 loss: 0.000435\n",
      "\n",
      "epoch_num: 46 batch_num: 1 loss: 0.000432\n",
      "\n",
      "epoch_num: 46 batch_num: 2 loss: 0.000412\n",
      "\n",
      "epoch_num: 46 batch_num: 3 loss: 0.000469\n",
      "\n",
      "epoch_num: 46 batch_num: 4 loss: 0.000400\n",
      "\n",
      "epoch_num: 46 batch_num: 5 loss: 0.000508\n",
      "\n",
      "Epoch is: 47\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 47 batch_num: 0 loss: 0.000734\n",
      "\n",
      "epoch_num: 47 batch_num: 1 loss: 0.000417\n",
      "\n",
      "epoch_num: 47 batch_num: 2 loss: 0.000304\n",
      "\n",
      "epoch_num: 47 batch_num: 3 loss: 0.000806\n",
      "\n",
      "epoch_num: 47 batch_num: 4 loss: 0.000676\n",
      "\n",
      "epoch_num: 47 batch_num: 5 loss: 0.000853\n",
      "\n",
      "Epoch is: 48\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 48 batch_num: 0 loss: 0.000669\n",
      "\n",
      "epoch_num: 48 batch_num: 1 loss: 0.000445\n",
      "\n",
      "epoch_num: 48 batch_num: 2 loss: 0.000368\n",
      "\n",
      "epoch_num: 48 batch_num: 3 loss: 0.000372\n",
      "\n",
      "epoch_num: 48 batch_num: 4 loss: 0.000631\n",
      "\n",
      "epoch_num: 48 batch_num: 5 loss: 0.000350\n",
      "\n",
      "Epoch is: 49\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 49 batch_num: 0 loss: 0.000302\n",
      "\n",
      "epoch_num: 49 batch_num: 1 loss: 0.000456\n",
      "\n",
      "epoch_num: 49 batch_num: 2 loss: 0.000434\n",
      "\n",
      "epoch_num: 49 batch_num: 3 loss: 0.000604\n",
      "\n",
      "epoch_num: 49 batch_num: 4 loss: 0.000373\n",
      "\n",
      "epoch_num: 49 batch_num: 5 loss: 0.000319\n",
      "\n",
      "Epoch is: 50\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 50 batch_num: 0 loss: 0.000327\n",
      "\n",
      "epoch_num: 50 batch_num: 1 loss: 0.000558\n",
      "\n",
      "epoch_num: 50 batch_num: 2 loss: 0.000418\n",
      "\n",
      "epoch_num: 50 batch_num: 3 loss: 0.000445\n",
      "\n",
      "epoch_num: 50 batch_num: 4 loss: 0.000335\n",
      "\n",
      "epoch_num: 50 batch_num: 5 loss: 0.000370\n",
      "\n",
      "Epoch is: 51\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 51 batch_num: 0 loss: 0.000386\n",
      "\n",
      "epoch_num: 51 batch_num: 1 loss: 0.000607\n",
      "\n",
      "epoch_num: 51 batch_num: 2 loss: 0.000582\n",
      "\n",
      "epoch_num: 51 batch_num: 3 loss: 0.000326\n",
      "\n",
      "epoch_num: 51 batch_num: 4 loss: 0.000307\n",
      "\n",
      "epoch_num: 51 batch_num: 5 loss: 0.000785\n",
      "\n",
      "Epoch is: 52\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 52 batch_num: 0 loss: 0.000540\n",
      "\n",
      "epoch_num: 52 batch_num: 1 loss: 0.000289\n",
      "\n",
      "epoch_num: 52 batch_num: 2 loss: 0.000236\n",
      "\n",
      "epoch_num: 52 batch_num: 3 loss: 0.000275\n",
      "\n",
      "epoch_num: 52 batch_num: 4 loss: 0.000306\n",
      "\n",
      "epoch_num: 52 batch_num: 5 loss: 0.000501\n",
      "\n",
      "Epoch is: 53\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 53 batch_num: 0 loss: 0.000557\n",
      "\n",
      "epoch_num: 53 batch_num: 1 loss: 0.000438\n",
      "\n",
      "epoch_num: 53 batch_num: 2 loss: 0.000331\n",
      "\n",
      "epoch_num: 53 batch_num: 3 loss: 0.000432\n",
      "\n",
      "epoch_num: 53 batch_num: 4 loss: 0.000470\n",
      "\n",
      "epoch_num: 53 batch_num: 5 loss: 0.000444\n",
      "\n",
      "Epoch is: 54\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 54 batch_num: 0 loss: 0.000374\n",
      "\n",
      "epoch_num: 54 batch_num: 1 loss: 0.000263\n",
      "\n",
      "epoch_num: 54 batch_num: 2 loss: 0.000289\n",
      "\n",
      "epoch_num: 54 batch_num: 3 loss: 0.000525\n",
      "\n",
      "epoch_num: 54 batch_num: 4 loss: 0.000320\n",
      "\n",
      "epoch_num: 54 batch_num: 5 loss: 0.000325\n",
      "\n",
      "Epoch is: 55\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 55 batch_num: 0 loss: 0.000457\n",
      "\n",
      "epoch_num: 55 batch_num: 1 loss: 0.000452\n",
      "\n",
      "epoch_num: 55 batch_num: 2 loss: 0.000384\n",
      "\n",
      "epoch_num: 55 batch_num: 3 loss: 0.000302\n",
      "\n",
      "epoch_num: 55 batch_num: 4 loss: 0.000308\n",
      "\n",
      "epoch_num: 55 batch_num: 5 loss: 0.000447\n",
      "\n",
      "Epoch is: 56\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 56 batch_num: 0 loss: 0.000445\n",
      "\n",
      "epoch_num: 56 batch_num: 1 loss: 0.000395\n",
      "\n",
      "epoch_num: 56 batch_num: 2 loss: 0.000234\n",
      "\n",
      "epoch_num: 56 batch_num: 3 loss: 0.000215\n",
      "\n",
      "epoch_num: 56 batch_num: 4 loss: 0.000311\n",
      "\n",
      "epoch_num: 56 batch_num: 5 loss: 0.000291\n",
      "\n",
      "Epoch is: 57\n",
      "\n",
      "Number of batches: 6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num: 57 batch_num: 0 loss: 0.000480\n",
      "\n",
      "epoch_num: 57 batch_num: 1 loss: 0.000232\n",
      "\n",
      "epoch_num: 57 batch_num: 2 loss: 0.000250\n",
      "\n",
      "epoch_num: 57 batch_num: 3 loss: 0.000307\n",
      "\n",
      "epoch_num: 57 batch_num: 4 loss: 0.000747\n",
      "\n",
      "epoch_num: 57 batch_num: 5 loss: 0.000530\n",
      "\n",
      "Epoch is: 58\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 58 batch_num: 0 loss: 0.000376\n",
      "\n",
      "epoch_num: 58 batch_num: 1 loss: 0.000454\n",
      "\n",
      "epoch_num: 58 batch_num: 2 loss: 0.000570\n",
      "\n",
      "epoch_num: 58 batch_num: 3 loss: 0.000551\n",
      "\n",
      "epoch_num: 58 batch_num: 4 loss: 0.000597\n",
      "\n",
      "epoch_num: 58 batch_num: 5 loss: 0.000356\n",
      "\n",
      "Epoch is: 59\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 59 batch_num: 0 loss: 0.000329\n",
      "\n",
      "epoch_num: 59 batch_num: 1 loss: 0.000269\n",
      "\n",
      "epoch_num: 59 batch_num: 2 loss: 0.000259\n",
      "\n",
      "epoch_num: 59 batch_num: 3 loss: 0.000342\n",
      "\n",
      "epoch_num: 59 batch_num: 4 loss: 0.000383\n",
      "\n",
      "epoch_num: 59 batch_num: 5 loss: 0.000459\n",
      "\n",
      "Epoch is: 60\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 60 batch_num: 0 loss: 0.000320\n",
      "\n",
      "epoch_num: 60 batch_num: 1 loss: 0.000216\n",
      "\n",
      "epoch_num: 60 batch_num: 2 loss: 0.000645\n",
      "\n",
      "epoch_num: 60 batch_num: 3 loss: 0.000592\n",
      "\n",
      "epoch_num: 60 batch_num: 4 loss: 0.000406\n",
      "\n",
      "epoch_num: 60 batch_num: 5 loss: 0.000366\n",
      "\n",
      "Epoch is: 61\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 61 batch_num: 0 loss: 0.000368\n",
      "\n",
      "epoch_num: 61 batch_num: 1 loss: 0.000291\n",
      "\n",
      "epoch_num: 61 batch_num: 2 loss: 0.000288\n",
      "\n",
      "epoch_num: 61 batch_num: 3 loss: 0.000260\n",
      "\n",
      "epoch_num: 61 batch_num: 4 loss: 0.000389\n",
      "\n",
      "epoch_num: 61 batch_num: 5 loss: 0.000447\n",
      "\n",
      "Epoch is: 62\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 62 batch_num: 0 loss: 0.000328\n",
      "\n",
      "epoch_num: 62 batch_num: 1 loss: 0.000305\n",
      "\n",
      "epoch_num: 62 batch_num: 2 loss: 0.000551\n",
      "\n",
      "epoch_num: 62 batch_num: 3 loss: 0.000263\n",
      "\n",
      "epoch_num: 62 batch_num: 4 loss: 0.000322\n",
      "\n",
      "epoch_num: 62 batch_num: 5 loss: 0.000193\n",
      "\n",
      "Epoch is: 63\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 63 batch_num: 0 loss: 0.000240\n",
      "\n",
      "epoch_num: 63 batch_num: 1 loss: 0.000313\n",
      "\n",
      "epoch_num: 63 batch_num: 2 loss: 0.000331\n",
      "\n",
      "epoch_num: 63 batch_num: 3 loss: 0.000229\n",
      "\n",
      "epoch_num: 63 batch_num: 4 loss: 0.000449\n",
      "\n",
      "epoch_num: 63 batch_num: 5 loss: 0.000402\n",
      "\n",
      "Epoch is: 64\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 64 batch_num: 0 loss: 0.000289\n",
      "\n",
      "epoch_num: 64 batch_num: 1 loss: 0.000397\n",
      "\n",
      "epoch_num: 64 batch_num: 2 loss: 0.000292\n",
      "\n",
      "epoch_num: 64 batch_num: 3 loss: 0.000210\n",
      "\n",
      "epoch_num: 64 batch_num: 4 loss: 0.000365\n",
      "\n",
      "epoch_num: 64 batch_num: 5 loss: 0.000264\n",
      "\n",
      "Epoch is: 65\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 65 batch_num: 0 loss: 0.000301\n",
      "\n",
      "epoch_num: 65 batch_num: 1 loss: 0.000435\n",
      "\n",
      "epoch_num: 65 batch_num: 2 loss: 0.000336\n",
      "\n",
      "epoch_num: 65 batch_num: 3 loss: 0.000219\n",
      "\n",
      "epoch_num: 65 batch_num: 4 loss: 0.000271\n",
      "\n",
      "epoch_num: 65 batch_num: 5 loss: 0.000361\n",
      "\n",
      "Epoch is: 66\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 66 batch_num: 0 loss: 0.000593\n",
      "\n",
      "epoch_num: 66 batch_num: 1 loss: 0.000498\n",
      "\n",
      "epoch_num: 66 batch_num: 2 loss: 0.004877\n",
      "\n",
      "epoch_num: 66 batch_num: 3 loss: 0.001065\n",
      "\n",
      "epoch_num: 66 batch_num: 4 loss: 0.000470\n",
      "\n",
      "epoch_num: 66 batch_num: 5 loss: 0.000414\n",
      "\n",
      "Epoch is: 67\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 67 batch_num: 0 loss: 0.000306\n",
      "\n",
      "epoch_num: 67 batch_num: 1 loss: 0.000566\n",
      "\n",
      "epoch_num: 67 batch_num: 2 loss: 0.000290\n",
      "\n",
      "epoch_num: 67 batch_num: 3 loss: 0.000511\n",
      "\n",
      "epoch_num: 67 batch_num: 4 loss: 0.000440\n",
      "\n",
      "epoch_num: 67 batch_num: 5 loss: 0.000422\n",
      "\n",
      "Epoch is: 68\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 68 batch_num: 0 loss: 0.000253\n",
      "\n",
      "epoch_num: 68 batch_num: 1 loss: 0.000230\n",
      "\n",
      "epoch_num: 68 batch_num: 2 loss: 0.000341\n",
      "\n",
      "epoch_num: 68 batch_num: 3 loss: 0.000352\n",
      "\n",
      "epoch_num: 68 batch_num: 4 loss: 0.000283\n",
      "\n",
      "epoch_num: 68 batch_num: 5 loss: 0.000237\n",
      "\n",
      "Epoch is: 69\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 69 batch_num: 0 loss: 0.000232\n",
      "\n",
      "epoch_num: 69 batch_num: 1 loss: 0.000867\n",
      "\n",
      "epoch_num: 69 batch_num: 2 loss: 0.000677\n",
      "\n",
      "epoch_num: 69 batch_num: 3 loss: 0.000592\n",
      "\n",
      "epoch_num: 69 batch_num: 4 loss: 0.000235\n",
      "\n",
      "epoch_num: 69 batch_num: 5 loss: 0.000254\n",
      "\n",
      "Epoch is: 70\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 70 batch_num: 0 loss: 0.000383\n",
      "\n",
      "epoch_num: 70 batch_num: 1 loss: 0.000516\n",
      "\n",
      "epoch_num: 70 batch_num: 2 loss: 0.000685\n",
      "\n",
      "epoch_num: 70 batch_num: 3 loss: 0.000309\n",
      "\n",
      "epoch_num: 70 batch_num: 4 loss: 0.000302\n",
      "\n",
      "epoch_num: 70 batch_num: 5 loss: 0.000242\n",
      "\n",
      "Epoch is: 71\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 71 batch_num: 0 loss: 0.000369\n",
      "\n",
      "epoch_num: 71 batch_num: 1 loss: 0.000281\n",
      "\n",
      "epoch_num: 71 batch_num: 2 loss: 0.000232\n",
      "\n",
      "epoch_num: 71 batch_num: 3 loss: 0.000202\n",
      "\n",
      "epoch_num: 71 batch_num: 4 loss: 0.000258\n",
      "\n",
      "epoch_num: 71 batch_num: 5 loss: 0.000650\n",
      "\n",
      "Epoch is: 72\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 72 batch_num: 0 loss: 0.000547\n",
      "\n",
      "epoch_num: 72 batch_num: 1 loss: 0.000780\n",
      "\n",
      "epoch_num: 72 batch_num: 2 loss: 0.000285\n",
      "\n",
      "epoch_num: 72 batch_num: 3 loss: 0.000150\n",
      "\n",
      "epoch_num: 72 batch_num: 4 loss: 0.000194\n",
      "\n",
      "epoch_num: 72 batch_num: 5 loss: 0.000478\n",
      "\n",
      "Epoch is: 73\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 73 batch_num: 0 loss: 0.000412\n",
      "\n",
      "epoch_num: 73 batch_num: 1 loss: 0.000330\n",
      "\n",
      "epoch_num: 73 batch_num: 2 loss: 0.000211\n",
      "\n",
      "epoch_num: 73 batch_num: 3 loss: 0.000220\n",
      "\n",
      "epoch_num: 73 batch_num: 4 loss: 0.000334\n",
      "\n",
      "epoch_num: 73 batch_num: 5 loss: 0.000211\n",
      "\n",
      "Epoch is: 74\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 74 batch_num: 0 loss: 0.000688\n",
      "\n",
      "epoch_num: 74 batch_num: 1 loss: 0.000596\n",
      "\n",
      "epoch_num: 74 batch_num: 2 loss: 0.000281\n",
      "\n",
      "epoch_num: 74 batch_num: 3 loss: 0.000745\n",
      "\n",
      "epoch_num: 74 batch_num: 4 loss: 0.000364\n",
      "\n",
      "epoch_num: 74 batch_num: 5 loss: 0.000337\n",
      "\n",
      "Epoch is: 75\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 75 batch_num: 0 loss: 0.000296\n",
      "\n",
      "epoch_num: 75 batch_num: 1 loss: 0.000196\n",
      "\n",
      "epoch_num: 75 batch_num: 2 loss: 0.000152\n",
      "\n",
      "epoch_num: 75 batch_num: 3 loss: 0.000141\n",
      "\n",
      "epoch_num: 75 batch_num: 4 loss: 0.000203\n",
      "\n",
      "epoch_num: 75 batch_num: 5 loss: 0.000147\n",
      "\n",
      "Epoch is: 76\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 76 batch_num: 0 loss: 0.000232\n",
      "\n",
      "epoch_num: 76 batch_num: 1 loss: 0.000170\n",
      "\n",
      "epoch_num: 76 batch_num: 2 loss: 0.000221\n",
      "\n",
      "epoch_num: 76 batch_num: 3 loss: 0.000270\n",
      "\n",
      "epoch_num: 76 batch_num: 4 loss: 0.000530\n",
      "\n",
      "epoch_num: 76 batch_num: 5 loss: 0.000439\n",
      "\n",
      "Epoch is: 77\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 77 batch_num: 0 loss: 0.000246\n",
      "\n",
      "epoch_num: 77 batch_num: 1 loss: 0.000500\n",
      "\n",
      "epoch_num: 77 batch_num: 2 loss: 0.000634\n",
      "\n",
      "epoch_num: 77 batch_num: 3 loss: 0.000742\n",
      "\n",
      "epoch_num: 77 batch_num: 4 loss: 0.000220\n",
      "\n",
      "epoch_num: 77 batch_num: 5 loss: 0.000164\n",
      "\n",
      "Epoch is: 78\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 78 batch_num: 0 loss: 0.000320\n",
      "\n",
      "epoch_num: 78 batch_num: 1 loss: 0.000260\n",
      "\n",
      "epoch_num: 78 batch_num: 2 loss: 0.000265\n",
      "\n",
      "epoch_num: 78 batch_num: 3 loss: 0.000190\n",
      "\n",
      "epoch_num: 78 batch_num: 4 loss: 0.000190\n",
      "\n",
      "epoch_num: 78 batch_num: 5 loss: 0.000238\n",
      "\n",
      "Epoch is: 79\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 79 batch_num: 0 loss: 0.000421\n",
      "\n",
      "epoch_num: 79 batch_num: 1 loss: 0.000432\n",
      "\n",
      "epoch_num: 79 batch_num: 2 loss: 0.000491\n",
      "\n",
      "epoch_num: 79 batch_num: 3 loss: 0.000421\n",
      "\n",
      "epoch_num: 79 batch_num: 4 loss: 0.000497\n",
      "\n",
      "epoch_num: 79 batch_num: 5 loss: 0.000362\n",
      "\n",
      "Epoch is: 80\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 80 batch_num: 0 loss: 0.000289\n",
      "\n",
      "epoch_num: 80 batch_num: 1 loss: 0.000540\n",
      "\n",
      "epoch_num: 80 batch_num: 2 loss: 0.000324\n",
      "\n",
      "epoch_num: 80 batch_num: 3 loss: 0.000192\n",
      "\n",
      "epoch_num: 80 batch_num: 4 loss: 0.000205\n",
      "\n",
      "epoch_num: 80 batch_num: 5 loss: 0.000144\n",
      "\n",
      "Epoch is: 81\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 81 batch_num: 0 loss: 0.000123\n",
      "\n",
      "epoch_num: 81 batch_num: 1 loss: 0.000158\n",
      "\n",
      "epoch_num: 81 batch_num: 2 loss: 0.000167\n",
      "\n",
      "epoch_num: 81 batch_num: 3 loss: 0.000202\n",
      "\n",
      "epoch_num: 81 batch_num: 4 loss: 0.000272\n",
      "\n",
      "epoch_num: 81 batch_num: 5 loss: 0.000281\n",
      "\n",
      "Epoch is: 82\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 82 batch_num: 0 loss: 0.000202\n",
      "\n",
      "epoch_num: 82 batch_num: 1 loss: 0.000362\n",
      "\n",
      "epoch_num: 82 batch_num: 2 loss: 0.000523\n",
      "\n",
      "epoch_num: 82 batch_num: 3 loss: 0.000515\n",
      "\n",
      "epoch_num: 82 batch_num: 4 loss: 0.000405\n",
      "\n",
      "epoch_num: 82 batch_num: 5 loss: 0.000223\n",
      "\n",
      "Epoch is: 83\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 83 batch_num: 0 loss: 0.000254\n",
      "\n",
      "epoch_num: 83 batch_num: 1 loss: 0.000261\n",
      "\n",
      "epoch_num: 83 batch_num: 2 loss: 0.000368\n",
      "\n",
      "epoch_num: 83 batch_num: 3 loss: 0.000188\n",
      "\n",
      "epoch_num: 83 batch_num: 4 loss: 0.000224\n",
      "\n",
      "epoch_num: 83 batch_num: 5 loss: 0.000247\n",
      "\n",
      "Epoch is: 84\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 84 batch_num: 0 loss: 0.000441\n",
      "\n",
      "epoch_num: 84 batch_num: 1 loss: 0.000472\n",
      "\n",
      "epoch_num: 84 batch_num: 2 loss: 0.000258\n",
      "\n",
      "epoch_num: 84 batch_num: 3 loss: 0.000145\n",
      "\n",
      "epoch_num: 84 batch_num: 4 loss: 0.000157\n",
      "\n",
      "epoch_num: 84 batch_num: 5 loss: 0.000147\n",
      "\n",
      "Epoch is: 85\n",
      "\n",
      "Number of batches: 6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num: 85 batch_num: 0 loss: 0.000265\n",
      "\n",
      "epoch_num: 85 batch_num: 1 loss: 0.000685\n",
      "\n",
      "epoch_num: 85 batch_num: 2 loss: 0.000511\n",
      "\n",
      "epoch_num: 85 batch_num: 3 loss: 0.000185\n",
      "\n",
      "epoch_num: 85 batch_num: 4 loss: 0.000285\n",
      "\n",
      "epoch_num: 85 batch_num: 5 loss: 0.000226\n",
      "\n",
      "Epoch is: 86\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 86 batch_num: 0 loss: 0.000532\n",
      "\n",
      "epoch_num: 86 batch_num: 1 loss: 0.000292\n",
      "\n",
      "epoch_num: 86 batch_num: 2 loss: 0.000362\n",
      "\n",
      "epoch_num: 86 batch_num: 3 loss: 0.000481\n",
      "\n",
      "epoch_num: 86 batch_num: 4 loss: 0.000362\n",
      "\n",
      "epoch_num: 86 batch_num: 5 loss: 0.000232\n",
      "\n",
      "Epoch is: 87\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 87 batch_num: 0 loss: 0.000583\n",
      "\n",
      "epoch_num: 87 batch_num: 1 loss: 0.000258\n",
      "\n",
      "epoch_num: 87 batch_num: 2 loss: 0.000189\n",
      "\n",
      "epoch_num: 87 batch_num: 3 loss: 0.000373\n",
      "\n",
      "epoch_num: 87 batch_num: 4 loss: 0.000233\n",
      "\n",
      "epoch_num: 87 batch_num: 5 loss: 0.000202\n",
      "\n",
      "Epoch is: 88\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 88 batch_num: 0 loss: 0.000350\n",
      "\n",
      "epoch_num: 88 batch_num: 1 loss: 0.000313\n",
      "\n",
      "epoch_num: 88 batch_num: 2 loss: 0.000423\n",
      "\n",
      "epoch_num: 88 batch_num: 3 loss: 0.000235\n",
      "\n",
      "epoch_num: 88 batch_num: 4 loss: 0.000222\n",
      "\n",
      "epoch_num: 88 batch_num: 5 loss: 0.000371\n",
      "\n",
      "Epoch is: 89\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 89 batch_num: 0 loss: 0.000211\n",
      "\n",
      "epoch_num: 89 batch_num: 1 loss: 0.000293\n",
      "\n",
      "epoch_num: 89 batch_num: 2 loss: 0.000215\n",
      "\n",
      "epoch_num: 89 batch_num: 3 loss: 0.000414\n",
      "\n",
      "epoch_num: 89 batch_num: 4 loss: 0.000341\n",
      "\n",
      "epoch_num: 89 batch_num: 5 loss: 0.000353\n",
      "\n",
      "Epoch is: 90\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 90 batch_num: 0 loss: 0.000205\n",
      "\n",
      "epoch_num: 90 batch_num: 1 loss: 0.000210\n",
      "\n",
      "epoch_num: 90 batch_num: 2 loss: 0.000258\n",
      "\n",
      "epoch_num: 90 batch_num: 3 loss: 0.000408\n",
      "\n",
      "epoch_num: 90 batch_num: 4 loss: 0.000318\n",
      "\n",
      "epoch_num: 90 batch_num: 5 loss: 0.000226\n",
      "\n",
      "Epoch is: 91\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 91 batch_num: 0 loss: 0.000209\n",
      "\n",
      "epoch_num: 91 batch_num: 1 loss: 0.000177\n",
      "\n",
      "epoch_num: 91 batch_num: 2 loss: 0.000220\n",
      "\n",
      "epoch_num: 91 batch_num: 3 loss: 0.000282\n",
      "\n",
      "epoch_num: 91 batch_num: 4 loss: 0.000322\n",
      "\n",
      "epoch_num: 91 batch_num: 5 loss: 0.000304\n",
      "\n",
      "Epoch is: 92\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 92 batch_num: 0 loss: 0.000141\n",
      "\n",
      "epoch_num: 92 batch_num: 1 loss: 0.000350\n",
      "\n",
      "epoch_num: 92 batch_num: 2 loss: 0.000163\n",
      "\n",
      "epoch_num: 92 batch_num: 3 loss: 0.000312\n",
      "\n",
      "epoch_num: 92 batch_num: 4 loss: 0.000267\n",
      "\n",
      "epoch_num: 92 batch_num: 5 loss: 0.000284\n",
      "\n",
      "Epoch is: 93\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 93 batch_num: 0 loss: 0.000211\n",
      "\n",
      "epoch_num: 93 batch_num: 1 loss: 0.000245\n",
      "\n",
      "epoch_num: 93 batch_num: 2 loss: 0.000359\n",
      "\n",
      "epoch_num: 93 batch_num: 3 loss: 0.000364\n",
      "\n",
      "epoch_num: 93 batch_num: 4 loss: 0.000203\n",
      "\n",
      "epoch_num: 93 batch_num: 5 loss: 0.000263\n",
      "\n",
      "Epoch is: 94\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 94 batch_num: 0 loss: 0.000186\n",
      "\n",
      "epoch_num: 94 batch_num: 1 loss: 0.000285\n",
      "\n",
      "epoch_num: 94 batch_num: 2 loss: 0.000246\n",
      "\n",
      "epoch_num: 94 batch_num: 3 loss: 0.000444\n",
      "\n",
      "epoch_num: 94 batch_num: 4 loss: 0.000291\n",
      "\n",
      "epoch_num: 94 batch_num: 5 loss: 0.000394\n",
      "\n",
      "Epoch is: 95\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 95 batch_num: 0 loss: 0.000315\n",
      "\n",
      "epoch_num: 95 batch_num: 1 loss: 0.000153\n",
      "\n",
      "epoch_num: 95 batch_num: 2 loss: 0.000192\n",
      "\n",
      "epoch_num: 95 batch_num: 3 loss: 0.000165\n",
      "\n",
      "epoch_num: 95 batch_num: 4 loss: 0.000208\n",
      "\n",
      "epoch_num: 95 batch_num: 5 loss: 0.000181\n",
      "\n",
      "Epoch is: 96\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 96 batch_num: 0 loss: 0.000209\n",
      "\n",
      "epoch_num: 96 batch_num: 1 loss: 0.000206\n",
      "\n",
      "epoch_num: 96 batch_num: 2 loss: 0.000139\n",
      "\n",
      "epoch_num: 96 batch_num: 3 loss: 0.000182\n",
      "\n",
      "epoch_num: 96 batch_num: 4 loss: 0.000188\n",
      "\n",
      "epoch_num: 96 batch_num: 5 loss: 0.000340\n",
      "\n",
      "Epoch is: 97\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 97 batch_num: 0 loss: 0.000398\n",
      "\n",
      "epoch_num: 97 batch_num: 1 loss: 0.000395\n",
      "\n",
      "epoch_num: 97 batch_num: 2 loss: 0.000206\n",
      "\n",
      "epoch_num: 97 batch_num: 3 loss: 0.000119\n",
      "\n",
      "epoch_num: 97 batch_num: 4 loss: 0.000168\n",
      "\n",
      "epoch_num: 97 batch_num: 5 loss: 0.000180\n",
      "\n",
      "Epoch is: 98\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 98 batch_num: 0 loss: 0.000194\n",
      "\n",
      "epoch_num: 98 batch_num: 1 loss: 0.000127\n",
      "\n",
      "epoch_num: 98 batch_num: 2 loss: 0.000117\n",
      "\n",
      "epoch_num: 98 batch_num: 3 loss: 0.000243\n",
      "\n",
      "epoch_num: 98 batch_num: 4 loss: 0.000187\n",
      "\n",
      "epoch_num: 98 batch_num: 5 loss: 0.000291\n",
      "\n",
      "Epoch is: 99\n",
      "\n",
      "Number of batches: 6\n",
      "\n",
      "epoch_num: 99 batch_num: 0 loss: 0.000365\n",
      "\n",
      "epoch_num: 99 batch_num: 1 loss: 0.000142\n",
      "\n",
      "epoch_num: 99 batch_num: 2 loss: 0.000132\n",
      "\n",
      "epoch_num: 99 batch_num: 3 loss: 0.000187\n",
      "\n",
      "epoch_num: 99 batch_num: 4 loss: 0.000181\n",
      "\n",
      "epoch_num: 99 batch_num: 5 loss: 0.000140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,300):\n",
    "    \n",
    "    train_X,train_Y=shuffle(x_train,y_train)\n",
    "    print (\"Epoch is: %d\\n\" % epoch)\n",
    "    batch_size=64\n",
    "    print (\"Number of batches: %d\\n\" % int(len(train_X)/batch_size))\n",
    "    num_batches=int(len(train_X)/batch_size)\n",
    "    for batch in range(num_batches):    \n",
    "        batch_train_X=train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
    "        batch_train_Y=train_Y[batch*batch_size:min((batch+1)*batch_size,len(train_Y))]\n",
    "        loss=autoencoder.train_on_batch(batch_train_X,batch_train_Y)\n",
    "        print ('epoch_num: %d batch_num: %d loss: %f\\n' % (epoch,batch,loss))\n",
    "\n",
    "    autoencoder.save_weights(\"fabric_autoen.h5\")\n",
    "    if(epoch%2==0):\n",
    "        x_test,y_test=shuffle(x_test,y_test)\n",
    "        decoded_imgs=autoencoder.predict(x_test[:2])\n",
    "        temp = np.zeros([128, 128*3,3])\n",
    "        temp[:, :128,:1] = x_test[0,:,:,:1]\n",
    "        temp[:, 128:128*2,:1] = y_test[0,:,:,:1]\n",
    "        temp[:, 128*2:,:1] = decoded_imgs[0,:,:,:1]\n",
    "        temp[:,:,1]=temp[:,:,0]\n",
    "        temp[:,:,2]=temp[:,:,0]\n",
    "        temp = temp*255\n",
    "        scipy.misc.imsave(CheckDir + str(epoch) + \".jpg\", temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
